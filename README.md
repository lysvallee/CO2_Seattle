# CO2 Seattle - Building Energy Benchmarking ğŸ™ï¸ğŸŒ

## 1. Project Overview ğŸ¯

This project is based on the data provided by the City of Seattle (https://data.seattle.gov/Built-Environment/Building-Energy-Benchmarking-Data-2015-Present/teqw-tu6e/about_data) with the following objectives:

- ğŸ”¬ Develop an application to predict energy consumption and CO2 emissions of buildings
- ğŸŒ± Support a long-term strategy to reduce greenhouse gas emissions
- ğŸ“Š Analyze the current state of Seattle's CO2 emissions and energy consumption
- ğŸ¤– Create a predictive tool for buildings without existing energy data

## 2. Technical Strategy and Challenges ğŸ§ 

Obtaining satisfactory predictions with this dataset was a complex challenge that required careful, strategic approach. Recognizing the limitations of computational resources, we developed a nuanced machine learning strategy:

### Feature Selection and Importance ğŸ”
- Utilized XGBoostRegressor with L1 regularization to rank feature importance
- Implemented a custom Recursive Feature Elimination (RFE) approach
- Focused on resource-efficient feature selection

### Data Preprocessing Techniques ğŸ§ª
- Explored various encoding methods (OneHotEncoder, Count Encoding, Target Encoding)
- Carefully managed categorical variables to avoid prediction contamination

### Error Metrics and Model Evaluation ğŸ“ˆ
- Minimized Mean Absolute Error (MAE) for practical prediction accuracy
- Used Root Mean Square Error (RMSE) to understand outlier impact
- Maintained RÂ² score for comparative analysis

### Key Insights ğŸ’¡
- Natural gas emerged as the most significant emission contributor
- Discovered that building age and ENERGY STAR score have minimal predictive power

## 3. Project Structure ğŸ“‚

```
.
â”œâ”€â”€ eda/
â”‚   â””â”€â”€ CO2_EDA.ipynb           # Exploratory Data Analysis
â”œâ”€â”€ predictions/
â”‚   â””â”€â”€ CO2_predictions.ipynb   # Prediction model notebook
â”œâ”€â”€ images/
â”‚   â””â”€â”€ schÃ©ma_fonctionnel_seattle.png  # Functional diagram
â”œâ”€â”€ main.py                     # FastAPI application
â””â”€â”€ requirements.txt            # Project dependencies
```

## 4. Technical Stack ğŸ› ï¸

- **Web Framework**: FastAPI
- **Machine Learning**: 
  - Scikit-learn
  - Scikit-optimize
  - XGBoost
- **Visualization**: 
  - Plotly
- **Deployment**: 
  - Docker
  - Azure Cloud Services

## 5. Installation and Usage ğŸš€

1. Clone the repository
   ```bash
   git clone https://github.com/yourusername/CO2_Seattle.git
   cd CO2_Seattle
   ```

2. Install dependencies
   ```bash
   pip install -r requirements.txt
   ```

3. Run the application
   ```bash
   uvicorn main:app --reload
   ```

**Access Points**:
- Dashboard: `/dashboard/`
- Predictions: `/predictions/`
- Recommendations: `/recommendations/`


*Note: This project is more geared toward data practitioners than holders of a PhD in Statistics. But if you consider yourself the God of Heteroscedasticity, you might enjoy seeing the sufferings of mere mortals! ğŸ¤“*

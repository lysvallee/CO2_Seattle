{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Stratégie adoptée\n",
        "\n",
        "Obtenir des prédiction satisfaisantes avec ce dataset relève du défi. Si nous disposions d'une ferme de serveurs, nous pourrions tenter d'utiliser RFECV pour sélectionner automatiquement les meilleures features. A défaut, nous allons"
      ],
      "metadata": {
        "id": "Ko1cHLoGyNtV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1.Installation de scikit-optimize\n",
        "\n",
        "Cette librairie, créée par les développeurs de scikit-learn, nous permettra d'effectuer une recherche d'optimisation bayésienne sur l'espace des hyperparamètres.\n",
        "https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html"
      ],
      "metadata": {
        "id": "ZYMhpJM3A9tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogbcRifIUTj9",
        "outputId": "820826fa-749b-4389-caf9-1a2611b0bfdf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.10/dist-packages (0.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.1)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (23.7.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBIp49hNtbxd",
        "outputId": "c85ff7cf-0219-41e1-b2d3-130c70e198d9"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: category_encoders in /usr/local/lib/python3.10/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.10.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.13.5)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2022.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.2.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (23.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2.Chargement des librairies"
      ],
      "metadata": {
        "id": "XlJEYPbF_F6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# System\n",
        "import os\n",
        "from joblib import dump, load\n",
        "from google.colab import files\n",
        "import warnings\n",
        "\n",
        "# Data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Graphics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine learning - Preprocessing\n",
        "from sklearn.impute import KNNImputer, SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, QuantileTransformer, PowerTransformer, FunctionTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from category_encoders.glmm import GLMMEncoder\n",
        "\n",
        "# Machine learning - Automatisation\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn import set_config\n",
        "\n",
        "# Machine learning - Metrics\n",
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "\n",
        "# Machine learning - Models\n",
        "import xgboost as xgb\n",
        "from sklearn.linear_model import HuberRegressor, TheilSenRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor, HistGradientBoostingRegressor, RandomForestRegressor, AdaBoostRegressor\n",
        "from sklearn.multioutput import RegressorChain\n",
        "\n",
        "# Machine learning - Model selection\n",
        "from sklearn.model_selection import train_test_split, LearningCurveDisplay, ShuffleSplit\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer, Categorical\n",
        "from sklearn.exceptions import NotFittedError"
      ],
      "metadata": {
        "id": "7vvsfdZD03_3"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Silence warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "9fRbVhbVy9ZB"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Hmic_Iyv8jY_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3.Chargement du dataset"
      ],
      "metadata": {
        "id": "YPaI2at1Ddwx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "6m-_7Oyo51xK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a435b197-d3ce-45f6-b444-8c0496be9c8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/CO2\n",
            "Le répertoire courant est : /content/drive/MyDrive/CO2 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mount GoogleDrive and set the files path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd '/content/drive/MyDrive/CO2'\n",
        "path = os.getcwd()\n",
        "print(f\"Le répertoire courant est : {path} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('co2_eda.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yAFFXyWiZCV",
        "outputId": "9c423780-4ed8-4d69-ea74-51f0eff5947f"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3305 entries, 0 to 3304\n",
            "Data columns (total 31 columns):\n",
            " #   Column                         Non-Null Count  Dtype  \n",
            "---  ------                         --------------  -----  \n",
            " 0   buildingtype                   3305 non-null   object \n",
            " 1   primarypropertytype            3305 non-null   object \n",
            " 2   taxparcelidentificationnumber  3305 non-null   object \n",
            " 3   councildistrictcode            3305 non-null   int64  \n",
            " 4   neighborhood                   3305 non-null   object \n",
            " 5   numberofbuildings              3305 non-null   int64  \n",
            " 6   numberoffloors                 3305 non-null   int64  \n",
            " 7   propertygfatotal               3305 non-null   int64  \n",
            " 8   propertygfaparking             3305 non-null   int64  \n",
            " 9   propertygfabuilding_s          3305 non-null   int64  \n",
            " 10  listofallpropertyusetypes      3305 non-null   object \n",
            " 11  largestpropertyusetype         3294 non-null   object \n",
            " 12  largestpropertyusetypegfa      3294 non-null   float64\n",
            " 13  energystarscore                2500 non-null   float64\n",
            " 14  siteeui_kbtu_sf                3305 non-null   float64\n",
            " 15  siteeuiwn_kbtu_sf              3305 non-null   float64\n",
            " 16  sourceeui_kbtu_sf              3305 non-null   float64\n",
            " 17  sourceeuiwn_kbtu_sf            3305 non-null   float64\n",
            " 18  siteenergyuse_kbtu             3305 non-null   float64\n",
            " 19  siteenergyusewn_kbtu           3305 non-null   float64\n",
            " 20  steam                          3305 non-null   bool   \n",
            " 21  electricity                    3305 non-null   bool   \n",
            " 22  naturalgas                     3305 non-null   bool   \n",
            " 23  defaultdata                    3305 non-null   bool   \n",
            " 24  compliancestatus               3305 non-null   object \n",
            " 25  totalghgemissions              3305 non-null   float64\n",
            " 26  zipcode                        3305 non-null   float64\n",
            " 27  latitude                       3305 non-null   float64\n",
            " 28  longitude                      3305 non-null   float64\n",
            " 29  age                            3305 non-null   int64  \n",
            " 30  source_site                    3305 non-null   float64\n",
            "dtypes: bool(4), float64(13), int64(7), object(7)\n",
            "memory usage: 710.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix dtype changes after CSV exporting\n",
        "df['zipcode'] = df['zipcode'].astype('object')\n",
        "df['councildistrictcode'] = df['councildistrictcode'].astype('object')\n",
        "df['energystarscore'] = df['energystarscore'].astype('object')\n",
        "# Turn the boolean columns into categorical for target encoding\n",
        "for column in df.select_dtypes(include=['bool']).columns:\n",
        "  df[column] = df[column].astype('object')\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "Hg8ZOfqIqGLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ffc178-5aad-4131-b9d9-0a3514516601"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "buildingtype                      object\n",
              "primarypropertytype               object\n",
              "taxparcelidentificationnumber     object\n",
              "councildistrictcode               object\n",
              "neighborhood                      object\n",
              "numberofbuildings                  int64\n",
              "numberoffloors                     int64\n",
              "propertygfatotal                   int64\n",
              "propertygfaparking                 int64\n",
              "propertygfabuilding_s              int64\n",
              "listofallpropertyusetypes         object\n",
              "largestpropertyusetype            object\n",
              "largestpropertyusetypegfa        float64\n",
              "energystarscore                   object\n",
              "siteeui_kbtu_sf                  float64\n",
              "siteeuiwn_kbtu_sf                float64\n",
              "sourceeui_kbtu_sf                float64\n",
              "sourceeuiwn_kbtu_sf              float64\n",
              "siteenergyuse_kbtu               float64\n",
              "siteenergyusewn_kbtu             float64\n",
              "steam                             object\n",
              "electricity                       object\n",
              "naturalgas                        object\n",
              "defaultdata                       object\n",
              "compliancestatus                  object\n",
              "totalghgemissions                float64\n",
              "zipcode                           object\n",
              "latitude                         float64\n",
              "longitude                        float64\n",
              "age                                int64\n",
              "source_site                      float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4.Gestion des targets multiples\n",
        "\n",
        "Scikit-learn propose deux solutions :\n",
        "- MultiOutputRegressor si les variables sont traitées de façon indépendante.\n",
        "- RegressorChain si elles sont dépendantes.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/multiclass.html\n",
        "\n",
        "Il y a une corrélation élevée (0.873) entre la consommation énergétique et les émissions de CO2, donc on choisira la seconde option.\n",
        "\n",
        "Comme nous prédirons les émissions après la consommation, cela nous mène à créer une variable targets commençant par la colonne siteenergyuse_kbtu :"
      ],
      "metadata": {
        "id": "i9-YgJPOv54s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the targets and features\n",
        "targets = ['source_site', 'sourceeuiwn_kbtu_sf', 'sourceeui_kbtu_sf', 'siteeuiwn_kbtu_sf', 'siteeui_kbtu_sf', 'siteenergyusewn_kbtu', 'siteenergyuse_kbtu', 'totalghgemissions']\n",
        "y = df[targets]\n",
        "X = df.drop(targets, axis=1)"
      ],
      "metadata": {
        "id": "HE87k9iOgukb"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5.Preprocessing des données"
      ],
      "metadata": {
        "id": "ljiglFPhEHzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L'EDA a montré que certaines variables étaient loin d'avoir une distribution gaussienne. Pour y remédier, le QuantileTransformer semble préférable au PowerTransformer parce qu'il est efficace quelle que soit la distribution de départ : https://scikit-learn.org/stable/modules/preprocessing.html#mapping-to-a-gaussian-distribution"
      ],
      "metadata": {
        "id": "ZtNlnzPmYeuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply QuantileTransformer to the target variables\n",
        "qt = PowerTransformer()\n",
        "y = qt.fit_transform(y)"
      ],
      "metadata": {
        "id": "2Sldwe2dwe5Y"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the transformed column corresponding to 'totalghgemissions'\n",
        "totalghg = pd.DataFrame(y[:, -1], columns=['totalghgemissions'])"
      ],
      "metadata": {
        "id": "c93cmYLS9fTf"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess categorical features with a target encoder based on 'totalghgemissions'\n",
        "def target_encoder(X=None):\n",
        "  X_cat = X.select_dtypes(include=['object'])\n",
        "  X_num = X.select_dtypes(include=['int64', 'float64'])\n",
        "  encoder = GLMMEncoder(verbose=2, drop_invariant=True, return_df=True, handle_missing='return_nan', randomized=True, binomial_target=False)\n",
        "  X_cat_encoded = encoder.fit_transform(X_cat, totalghg)\n",
        "  X = pd.concat([X_cat_encoded, X_num], axis=1)\n",
        "  return X\n",
        "\n",
        "X = target_encoder(X)\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "ccgJgRn_jX4p",
        "outputId": "93525dc4-e182-438e-bbf2-33bfdfd457bc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   buildingtype  primarypropertytype  taxparcelidentificationnumber  \\\n",
              "0     -0.136474             0.804226                       0.833267   \n",
              "1     -0.137007             0.753802                       0.936170   \n",
              "2     -0.140911             0.738589                       1.506272   \n",
              "3     -0.131241             0.779579                       0.836124   \n",
              "4     -0.137795             0.780034                       1.113745   \n",
              "\n",
              "   councildistrictcode  neighborhood  listofallpropertyusetypes  \\\n",
              "0             0.317365      0.595424                   0.608211   \n",
              "1             0.335091      0.641929                   0.227013   \n",
              "2             0.342045      0.609702                   0.625533   \n",
              "3             0.347425      0.542381                   0.593280   \n",
              "4             0.324118      0.552899                   0.512904   \n",
              "\n",
              "   largestpropertyusetype  energystarscore     steam  electricity  ...  \\\n",
              "0                0.724314         0.007962  0.673780     0.982584  ...   \n",
              "1                0.695067        -0.133604 -0.687989     0.979665  ...   \n",
              "2                0.773687         0.066868  0.686265     0.960563  ...   \n",
              "3                0.792823         0.041294  0.718829     0.945198  ...   \n",
              "4                0.735670        -0.044814 -0.715079     0.992460  ...   \n",
              "\n",
              "    zipcode  numberofbuildings  numberoffloors  propertygfatotal  \\\n",
              "0  0.819536                  1              12             88434   \n",
              "1  0.784291                  1              11            103566   \n",
              "2  0.800537                  1              41            956110   \n",
              "3  0.811492                  1              10             61320   \n",
              "4  0.482091                  1              18            175580   \n",
              "\n",
              "   propertygfaparking  propertygfabuilding_s  largestpropertyusetypegfa  \\\n",
              "0                   0                  88434                    88434.0   \n",
              "1               15064                  88502                    83880.0   \n",
              "2              196718                 759392                   756493.0   \n",
              "3                   0                  61320                    61320.0   \n",
              "4               62000                 113580                   123445.0   \n",
              "\n",
              "   latitude  longitude  age  \n",
              "0  47.61220 -122.33799   96  \n",
              "1  47.61317 -122.33393   27  \n",
              "2  47.61393 -122.33810   54  \n",
              "3  47.61412 -122.33664   97  \n",
              "4  47.61375 -122.34047   43  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-428e81f5-6ad6-4e4c-a1dd-8eb19a5611fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>buildingtype</th>\n",
              "      <th>primarypropertytype</th>\n",
              "      <th>taxparcelidentificationnumber</th>\n",
              "      <th>councildistrictcode</th>\n",
              "      <th>neighborhood</th>\n",
              "      <th>listofallpropertyusetypes</th>\n",
              "      <th>largestpropertyusetype</th>\n",
              "      <th>energystarscore</th>\n",
              "      <th>steam</th>\n",
              "      <th>electricity</th>\n",
              "      <th>...</th>\n",
              "      <th>zipcode</th>\n",
              "      <th>numberofbuildings</th>\n",
              "      <th>numberoffloors</th>\n",
              "      <th>propertygfatotal</th>\n",
              "      <th>propertygfaparking</th>\n",
              "      <th>propertygfabuilding_s</th>\n",
              "      <th>largestpropertyusetypegfa</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.136474</td>\n",
              "      <td>0.804226</td>\n",
              "      <td>0.833267</td>\n",
              "      <td>0.317365</td>\n",
              "      <td>0.595424</td>\n",
              "      <td>0.608211</td>\n",
              "      <td>0.724314</td>\n",
              "      <td>0.007962</td>\n",
              "      <td>0.673780</td>\n",
              "      <td>0.982584</td>\n",
              "      <td>...</td>\n",
              "      <td>0.819536</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>88434</td>\n",
              "      <td>0</td>\n",
              "      <td>88434</td>\n",
              "      <td>88434.0</td>\n",
              "      <td>47.61220</td>\n",
              "      <td>-122.33799</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.137007</td>\n",
              "      <td>0.753802</td>\n",
              "      <td>0.936170</td>\n",
              "      <td>0.335091</td>\n",
              "      <td>0.641929</td>\n",
              "      <td>0.227013</td>\n",
              "      <td>0.695067</td>\n",
              "      <td>-0.133604</td>\n",
              "      <td>-0.687989</td>\n",
              "      <td>0.979665</td>\n",
              "      <td>...</td>\n",
              "      <td>0.784291</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>103566</td>\n",
              "      <td>15064</td>\n",
              "      <td>88502</td>\n",
              "      <td>83880.0</td>\n",
              "      <td>47.61317</td>\n",
              "      <td>-122.33393</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.140911</td>\n",
              "      <td>0.738589</td>\n",
              "      <td>1.506272</td>\n",
              "      <td>0.342045</td>\n",
              "      <td>0.609702</td>\n",
              "      <td>0.625533</td>\n",
              "      <td>0.773687</td>\n",
              "      <td>0.066868</td>\n",
              "      <td>0.686265</td>\n",
              "      <td>0.960563</td>\n",
              "      <td>...</td>\n",
              "      <td>0.800537</td>\n",
              "      <td>1</td>\n",
              "      <td>41</td>\n",
              "      <td>956110</td>\n",
              "      <td>196718</td>\n",
              "      <td>759392</td>\n",
              "      <td>756493.0</td>\n",
              "      <td>47.61393</td>\n",
              "      <td>-122.33810</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.131241</td>\n",
              "      <td>0.779579</td>\n",
              "      <td>0.836124</td>\n",
              "      <td>0.347425</td>\n",
              "      <td>0.542381</td>\n",
              "      <td>0.593280</td>\n",
              "      <td>0.792823</td>\n",
              "      <td>0.041294</td>\n",
              "      <td>0.718829</td>\n",
              "      <td>0.945198</td>\n",
              "      <td>...</td>\n",
              "      <td>0.811492</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>61320</td>\n",
              "      <td>0</td>\n",
              "      <td>61320</td>\n",
              "      <td>61320.0</td>\n",
              "      <td>47.61412</td>\n",
              "      <td>-122.33664</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.137795</td>\n",
              "      <td>0.780034</td>\n",
              "      <td>1.113745</td>\n",
              "      <td>0.324118</td>\n",
              "      <td>0.552899</td>\n",
              "      <td>0.512904</td>\n",
              "      <td>0.735670</td>\n",
              "      <td>-0.044814</td>\n",
              "      <td>-0.715079</td>\n",
              "      <td>0.992460</td>\n",
              "      <td>...</td>\n",
              "      <td>0.482091</td>\n",
              "      <td>1</td>\n",
              "      <td>18</td>\n",
              "      <td>175580</td>\n",
              "      <td>62000</td>\n",
              "      <td>113580</td>\n",
              "      <td>123445.0</td>\n",
              "      <td>47.61375</td>\n",
              "      <td>-122.34047</td>\n",
              "      <td>43</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-428e81f5-6ad6-4e4c-a1dd-8eb19a5611fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-9d72d26a-50f9-4d17-923a-fac4f7f20668\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9d72d26a-50f9-4d17-923a-fac4f7f20668')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-9d72d26a-50f9-4d17-923a-fac4f7f20668 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-428e81f5-6ad6-4e4c-a1dd-8eb19a5611fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-428e81f5-6ad6-4e4c-a1dd-8eb19a5611fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add scaling to the processed\n",
        "transfo_cat = Pipeline(steps=[\n",
        "    ('scaling', PowerTransformer()),\n",
        "    ('imputation', SimpleImputer(strategy='constant', fill_value=-999)),\n",
        "    # ('scaling', QuantileTransformer(output_distribution='normal', random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "Rzwmaxv_jx0t"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the numerical features\n",
        "transfo_num = Pipeline(steps=[\n",
        "    ('scaling', PowerTransformer()),\n",
        "    ('imputation', SimpleImputer(strategy='constant', fill_value=-999)),\n",
        "    # ('scaling', QuantileTransformer(output_distribution='normal', random_state=42))\n",
        "])"
      ],
      "metadata": {
        "id": "uqmgntM7bGWS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour faciliter la modélisation, un CountVectorizer va tokeniser chaque type d'usage en utilisant le séparateur ', ' :"
      ],
      "metadata": {
        "id": "0AGu5IuunDYb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6.Création de la pipeline"
      ],
      "metadata": {
        "id": "F4ejpEGIrh5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chain_pipe(model=None, X=None, transfo_num=transfo_num, transfo_cat=transfo_cat):\n",
        "  '''Define the chain and preparation step, then concatenate'''\n",
        "  chain = RegressorChain(model, verbose=True)\n",
        "\n",
        "  num = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "  cat = X.select_dtypes(include=['object', 'bool']).columns\n",
        "\n",
        "  preparation = ColumnTransformer(\n",
        "  transformers=[\n",
        "  ('num', transfo_num, num),\n",
        "  ('cat', transfo_cat, cat),\n",
        "  ])\n",
        "\n",
        "  pipe = Pipeline(steps=[\n",
        "  ('preparation', preparation),\n",
        "  ('chain', chain)\n",
        "  ])\n",
        "  return pipe"
      ],
      "metadata": {
        "id": "tL3yAz9J2fmH"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#7.Choix de la métrique d'erreur\n",
        "\n",
        "A titre de comparaison, nous conserverons le R2 score, mais c'est en minimisant la MAE que nous parviendrons à obtenir les meilleurs résultats possibles avec le fichi"
      ],
      "metadata": {
        "id": "R8VgJOUfT1Eb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the scoring metric\n",
        "scoring='r2'\n",
        "# Evaluate the model\n",
        "def evaluate_model(opt=None, X=X, y=y, scoring=scoring):\n",
        "  # Find the best parameters\n",
        "  print('\\nCV parameters:')\n",
        "  for key, value in opt.best_params_.items():\n",
        "    print(\"{}: {}\".format(key, value))\n",
        "  # Evaluate cross validation performance\n",
        "  print('\\nCV score:', opt.best_score_.round(4))\n",
        "\n",
        "# Plot the learning curve\n",
        "def plot_curve(opt=None, X=X, y=y, scoring=scoring):\n",
        "  print('\\nComputing Cross Validation for the Learning Curve...\\n')\n",
        "  display = LearningCurveDisplay.from_estimator(\n",
        "    opt.best_estimator_,\n",
        "    X,\n",
        "    y,\n",
        "    train_sizes=np.linspace(0.1, 1.0, num=5),\n",
        "    cv=ShuffleSplit(n_splits=50, test_size=0.2, random_state=0),\n",
        "    score_type=\"both\",  # both train and test errors\n",
        "    scoring=scoring,\n",
        "    score_name=\"R2 score\",\n",
        "    std_display_style=\"fill_between\",\n",
        "    n_jobs=-1,\n",
        "    verbose=3\n",
        "    )\n",
        "  _ = display.ax_.set_title('Learning Curve')"
      ],
      "metadata": {
        "id": "_nyaGvvpT_mh"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(opt=None, X_test=None, y_test=None, targets=targets):\n",
        "  # Inverse transform the values to obtain an MAE that makes sense\n",
        "  y_pred = opt.predict(X_test)\n",
        "  y_pred_inv = qt.inverse_transform(y_pred)\n",
        "  y_test_inv = qt.inverse_transform(y_test)\n",
        "  # calculate R2 and MAE for each target\n",
        "  for i, target in enumerate(targets):\n",
        "    r2 = r2_score(y_test[:, i], y_pred[:, i])\n",
        "    mae = mean_absolute_error(y_test_inv[:, i], y_pred_inv[:, i])\n",
        "    print('\\n' + target)\n",
        "    print(\"R2 score:\", r2)\n",
        "    print(\"MAE:\", mae)\n",
        "  return r2"
      ],
      "metadata": {
        "id": "kjkUa6VJZFgj"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#8.Recherche des hyperparamètres"
      ],
      "metadata": {
        "id": "S_V62pO3V9oW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xg = {\n",
        "    # 'preparation__num__imputation__n_neighbors': Integer(2, 20),\n",
        "    'chain__base_estimator__n_estimators': Categorical([i for i in range(900, 1301, 50)]),\n",
        "    'chain__base_estimator__max_depth': Integer(2, 20),\n",
        "    'chain__base_estimator__learning_rate': Real(0.01, 1.0, prior='log-uniform'),\n",
        "    'chain__base_estimator__subsample': Real(0.1, 1.0, prior='uniform'),\n",
        "    'chain__base_estimator__colsample_bytree': Real(0.1, 1.0, prior='uniform'),\n",
        "    'chain__base_estimator__reg_alpha': Real(1e-5, 100, prior='log-uniform'),\n",
        "    'chain__base_estimator__reg_lambda': Real(1e-5, 100, prior='log-uniform'),\n",
        "}"
      ],
      "metadata": {
        "id": "nXup9al3_Adr"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_hyperparameters(model, search_space, test_size=0.2, scoring=scoring, targets=targets, X=X, y=y, *, plot=False, save=False):\n",
        "  '''print scores and return the feature importances if needed'''\n",
        "  # split into train and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "  #create the pipeline\n",
        "  pipe = chain_pipe(model, X)\n",
        "  # use BayesSearchCV to find optimal hyperparameters\n",
        "  opt = BayesSearchCV(\n",
        "    pipe,\n",
        "    search_space,\n",
        "    n_iter=10,\n",
        "    scoring=scoring,\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    n_points=10,\n",
        "    verbose=3,\n",
        "    error_score='raise',\n",
        "    random_state=42\n",
        "    )\n",
        "  opt.fit(X_train, y_train)\n",
        "  # get CV scores\n",
        "  evaluate_model(opt)\n",
        "  # get predictions\n",
        "  score = get_predictions(opt, X_test, y_test, targets)\n",
        "  # plot learning curve\n",
        "  if plot is True:\n",
        "    plot_curve(opt)\n",
        "  # Save the best model to a file\n",
        "  elif save is True:\n",
        "    file_name = str(model).split('(')[0] + '_' + str(len(X_train.columns)) + 'features.joblib'\n",
        "    dump(opt.best_estimator_, file_name)\n",
        "  return opt, score"
      ],
      "metadata": {
        "id": "d95R-4HPy-RW"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "opt, score = find_hyperparameters(xgb.XGBRegressor(missing=-999), xg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4paTDhVYFu7S",
        "outputId": "c03f03d8-6bb3-4229-c1ef-92d66c5363fd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "[Chain] ................... (1 of 8) Processing order 0, total=  12.9s\n",
            "[Chain] ................... (2 of 8) Processing order 1, total=  13.7s\n",
            "[Chain] ................... (3 of 8) Processing order 2, total=  14.0s\n",
            "[Chain] ................... (4 of 8) Processing order 3, total=  14.1s\n",
            "[Chain] ................... (5 of 8) Processing order 4, total=  14.3s\n",
            "[Chain] ................... (6 of 8) Processing order 5, total=  14.9s\n",
            "[Chain] ................... (7 of 8) Processing order 6, total=  15.3s\n",
            "[Chain] ................... (8 of 8) Processing order 7, total=  18.5s\n",
            "\n",
            "CV parameters:\n",
            "chain__base_estimator__colsample_bytree: 0.789064709375164\n",
            "chain__base_estimator__learning_rate: 0.03535340234201111\n",
            "chain__base_estimator__max_depth: 7\n",
            "chain__base_estimator__n_estimators: 950\n",
            "chain__base_estimator__reg_alpha: 0.0001432903492520826\n",
            "chain__base_estimator__reg_lambda: 1.0366573862631157\n",
            "chain__base_estimator__subsample: 0.9833537583348964\n",
            "\n",
            "CV score: 0.8111\n",
            "\n",
            "source_site\n",
            "R2 score: 0.5382356803461041\n",
            "MAE: 0.1998320022160137\n",
            "\n",
            "sourceeuiwn_kbtu_sf\n",
            "R2 score: 0.6449957099300846\n",
            "MAE: 48.47220549833673\n",
            "\n",
            "sourceeui_kbtu_sf\n",
            "R2 score: 0.63800763920336\n",
            "MAE: 48.36632299090903\n",
            "\n",
            "siteeuiwn_kbtu_sf\n",
            "R2 score: 0.8087553305264454\n",
            "MAE: 16.676901423527152\n",
            "\n",
            "siteeui_kbtu_sf\n",
            "R2 score: 0.8017499221561344\n",
            "MAE: 16.613799616826398\n",
            "\n",
            "siteenergyusewn_kbtu\n",
            "R2 score: 0.9427687381486258\n",
            "MAE: 1993103.540388483\n",
            "\n",
            "siteenergyuse_kbtu\n",
            "R2 score: 0.9394864899811821\n",
            "MAE: 1993745.9273364209\n",
            "\n",
            "totalghgemissions\n",
            "R2 score: 0.9799960440402592\n",
            "MAE: 46.41725179364122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop \"Run All\" from going beyond\n",
        "assert False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "gtTTJRzSC48O",
        "outputId": "b675f890-6625-4387-8f7e-11658e6cb263"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-9920640fa877>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Stop \"Run All\" from going beyond\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#9.Sélection des Features"
      ],
      "metadata": {
        "id": "-Jgk8qQX1Sh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(opt, X=X):\n",
        "  '''get feature importances once the ChainRegressor has been fit'''\n",
        "  # get the best model for the last target ('totalghgemissions')\n",
        "  estimators = opt.best_estimator_['chain'].estimators_\n",
        "  last_estimator = estimators[-1]\n",
        "  # get feature names (this step is necessary after preprocessing with OneHotEncoder and CountVectorizer)\n",
        "  try:\n",
        "    num_names = opt.best_estimator_['preparation'].named_transformers_['num'].named_steps['imputation'].get_feature_names_out().tolist()\n",
        "  # If there are no numerical features among the selected features\n",
        "  except ValueError:\n",
        "    num_names = []\n",
        "  try:\n",
        "    cat1_features = [feature for feature in ['primarypropertytype', 'largestpropertyusetype'] if feature in X.columns]\n",
        "    cat1_names = opt.best_estimator_['preparation'].named_transformers_['cat1'].named_steps['onehot'].get_feature_names_out(input_features=cat1_features).tolist()\n",
        "  except NotFittedError:\n",
        "    cat1_names = []\n",
        "  try:\n",
        "    cat2_names = ['listofallpropertyusetypes_' + x for x in list(opt.best_estimator_['preparation'].named_transformers_['cat2'].named_steps['vectorizer'].vocabulary_.keys())]\n",
        "  except AttributeError:\n",
        "    cat2_names = []\n",
        "  feature_names = num_names + cat1_names + cat2_names\n",
        "  # get feature importances\n",
        "  feature_importances = zip(feature_names, last_estimator.feature_importances_)\n",
        "  # group feature importances by base feature name\n",
        "  grouped_importances = {}\n",
        "  for name, importance in feature_importances:\n",
        "    if '_' in name:\n",
        "      base_name = name.split('_')[0]\n",
        "      if base_name in grouped_importances:\n",
        "        grouped_importances[base_name] += importance\n",
        "      else:\n",
        "        grouped_importances[base_name] = importance\n",
        "    else:\n",
        "      grouped_importances[name] = importance\n",
        "  return grouped_importances"
      ],
      "metadata": {
        "id": "D1fjkXP6uqD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(opt, X=X):\n",
        "  '''get feature importances once the ChainRegressor has been fit'''\n",
        "  # get the best model for the last target ('totalghgemissions')\n",
        "  estimators = opt.best_estimator_['chain'].estimators_\n",
        "  last_estimator = estimators[-1]\n",
        "  # get feature names (this step is necessary after preprocessing with OneHotEncoder and CountVectorizer)\n",
        "  try:\n",
        "    num_names = opt.best_estimator_['preparation'].named_transformers_['num'].named_steps['imputation'].get_feature_names_out().tolist()\n",
        "  # If there are no numerical features among the selected features\n",
        "  except ValueError:\n",
        "    num_names = []\n",
        "  try:\n",
        "    cat1_features = [feature for feature in ['primarypropertytype', 'largestpropertyusetype'] if feature in X.columns]\n",
        "    cat1_names = opt.best_estimator_['preparation'].named_transformers_['cat1'].named_steps['onehot'].get_feature_names_out(input_features=cat1_features).tolist()\n",
        "  except NotFittedError:\n",
        "    cat1_names = []\n",
        "  try:\n",
        "    cat2_names = ['listofallpropertyusetypes_' + x for x in list(opt.best_estimator_['preparation'].named_transformers_['cat2'].named_steps['vectorizer'].vocabulary_.keys())]\n",
        "  except AttributeError:\n",
        "    cat2_names = []\n",
        "  feature_names = num_names + cat1_names + cat2_names\n",
        "  # get feature importances\n",
        "  feature_importances = zip(feature_names, last_estimator.feature_importances_)\n",
        "  # group feature importances by base feature name\n",
        "  grouped_importances = {}\n",
        "  for name, importance in feature_importances:\n",
        "    if '_' in name:\n",
        "      base_name = name.split('_')[0]\n",
        "      if base_name in grouped_importances:\n",
        "        grouped_importances[base_name] += importance\n",
        "      else:\n",
        "        grouped_importances[base_name] = importance\n",
        "    else:\n",
        "      grouped_importances[name] = importance\n",
        "  return grouped_importances"
      ],
      "metadata": {
        "id": "MAx2TyIvkkYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort the feature importances by value in descending order\n",
        "feature_importances = get_features(opt)\n",
        "sorted_importances = sorted(feature_importances.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "# Extract the feature names and importances in separate lists\n",
        "features = [x[0] for x in sorted_importances]\n",
        "importances = [x[1] for x in sorted_importances]\n",
        "\n",
        "# Create a bar plot of the feature importances\n",
        "plt.bar(features, importances)\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('Feature')\n",
        "plt.ylabel('Importance')\n",
        "plt.title('Feature Importances')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W31fkVl5odE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete the 'missingindicator' flag which helped slightly during the fitting stage\n",
        "features.remove('missingindicator')"
      ],
      "metadata": {
        "id": "Enyi9sMp7Orx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selection = []\n",
        "score_curve = []\n",
        "selection_score = {}\n",
        "stop_count = 0\n",
        "for f, feature in enumerate(features):\n",
        "    selection.append(feature)\n",
        "    X_sel = X[selection]\n",
        "    opt, score = find_hyperparameters(xgb.XGBRegressor(), xg, X=X_sel, plot=False)\n",
        "    score_curve.append(score)\n",
        "    selection_score[score] = selection.copy()\n",
        "    f += 1\n",
        "    print('\\nFEATURE SELECTION\\n{}: {}\\n\\n\\n'.format(f, selection))\n",
        "    # Check the score curve for early stopping\n",
        "    if f >= 2:\n",
        "      # If the new score doesn't improve substantially from the previous one\n",
        "      if score_curve[-1] < score_curve[-2] + 0.02:\n",
        "        stop_count += 1\n",
        "      else:\n",
        "        stop_count = 0\n",
        "      # If the score has stabilized or decreased for 3 consecutive iterations, stop the loop\n",
        "      if stop_count >= 3:\n",
        "        print(\"Early stopping due to score stabilization or decrease\")\n",
        "        break"
      ],
      "metadata": {
        "id": "n1ivZ-KPldLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En comparant les modèles obtenant un R2 score équivalent, on s'aperçoit que celui correspondant à 6 features parvient à minimiser le mieux la MAE. C'est donc cette sélection de features que nous allons privilégier pour la suite des opérations."
      ],
      "metadata": {
        "id": "NykZWAz7rF4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selection = ['listofallpropertyusetypes', 'naturalgas', 'largestpropertyusetype', 'primarypropertytype', 'age', 'propertygfatotal']\n",
        "X = X[selection]"
      ],
      "metadata": {
        "id": "6TnjfNG9sKBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.Comparaison des modèles"
      ],
      "metadata": {
        "id": "xFLhgfCno0zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.1XGBoost"
      ],
      "metadata": {
        "id": "7r0RsYdieiDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.info()"
      ],
      "metadata": {
        "id": "MRFx9Ubz659k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.2Hubert"
      ],
      "metadata": {
        "id": "uTahnuTb-Szp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def robust_pipe(model=None, X=X, transfo_num=transfo_num, transfo_cat1=transfo_cat1, transfo_cat2=transfo_cat2):\n",
        "  '''Define the chain and preparation step, then concatenate'''\n",
        "  chain = RegressorChain(model)\n",
        "\n",
        "  preparation = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', transfo_num, X.select_dtypes(include=['int64', 'float64']).columns),\n",
        "        ('cat1', transfo_cat1, [feature for feature in ['primarypropertytype', 'largestpropertyusetype'] if feature in X.columns]),\n",
        "        ('cat2', transfo_cat2, ['listofallpropertyusetypes'] if 'listofallpropertyusetypes' in X.columns else [])\n",
        "        ])\n",
        "\n",
        "  pipe = Pipeline(steps=[\n",
        "    ('preparation', preparation),\n",
        "    ('chain', chain)\n",
        "    ])\n",
        "  return pipe"
      ],
      "metadata": {
        "id": "pueLvLVdDf3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the search space for HuberRegressor hyperparameters\n",
        "huber = {\n",
        "    'preparation__num__imputation__n_neighbors': Integer(2, 20),\n",
        "    'chain__base_estimator__epsilon': Real(1.0, 3.0, prior='uniform'),\n",
        "    'chain__base_estimator__alpha': Real(0.0001, 0.1, prior='log-uniform')\n",
        "}"
      ],
      "metadata": {
        "id": "4RWeeyPT_m0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-A9LvX72_qft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use HuberRegressor to fit a robust non-linear model to the data\n",
        "huber = HuberRegressor()\n",
        "huber.fit(opt.predict(X_train), y_train)\n",
        "\n",
        "# Evaluate the performance of the model on the test set\n",
        "y_pred = huber.predict(xgb.predict(X_test))\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE: %.2f\" % mse)"
      ],
      "metadata": {
        "id": "DZAwlaXo-W6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.2HistGradientBoostingRegressor"
      ],
      "metadata": {
        "id": "d748lBXV6Juk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hgb = {\n",
        "    'preparation__num__imputation__n_neighbors': Integer(2, 20),\n",
        "    'chain__base_estimator__loss': Categorical(['squared_error', 'absolute_error', 'poisson', 'quantile']),\n",
        "    'chain__base_estimator__learning_rate': Real(0.01, 0.1, prior='log-uniform'),\n",
        "    'chain__base_estimator__max_iter': Categorical([i for i in range(100, 1001, 50)]),\n",
        "    'chain__base_estimator__max_leaf_nodes': Integer(2, 500),\n",
        "    'chain__base_estimator__min_samples_leaf': Integer(1, 50),\n",
        "    'chain__base_estimator__l2_regularization': Real(1e-10, 1e-1, prior='log-uniform')\n",
        "}"
      ],
      "metadata": {
        "id": "IXULS9jC6R32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt, score = find_hyperparameters(HistGradientBoostingRegressor(), hgb)"
      ],
      "metadata": {
        "id": "DNRHZP7r7FAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the search space for hyperparameters\n",
        "n_features = X.shape[1]\n",
        "rf = {\n",
        "    'preparation__num__imputation__n_neighbors': Integer(2, 20),\n",
        "    'chain__base_estimator__n_estimators': Categorical([i for i in range(100, 1001, 50)]),\n",
        "    'chain__base_estimator__max_depth': Integer(2, 20),\n",
        "    'chain__base_estimator__min_samples_split': Integer(2, 10),\n",
        "    'chain__base_estimator__min_samples_leaf': Integer(1, 10),\n",
        "    'chain__base_estimator__max_features': Integer(int(np.log2(n_features)), n_features),\n",
        "    'chain__base_estimator__max_samples': Real(0.1, 1.0, prior='log-uniform')\n",
        "}"
      ],
      "metadata": {
        "id": "SOjIMldeu9dU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#10.1 RandomForestRegressor\n",
        "\n",
        "> Indented block\n",
        "\n"
      ],
      "metadata": {
        "id": "-1VEbx0sutIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt, X_test, y_test = find_hyperparameters(RandomForestRegressor(), rf)"
      ],
      "metadata": {
        "id": "RWWqcYTgvRX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#11.Export du modèle choisi"
      ],
      "metadata": {
        "id": "DLNrD8s6ofma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the best hyperparameters\n",
        "best_pipe = opt.best_estimator_\n",
        "# Fit the pipeline on the original dataset\n",
        "X = df.drop(targets, axis=1)\n",
        "X = target_encoder(X)\n",
        "best_pipe.fit(X, y)\n",
        "# Save the resulting model to a file\n",
        "dump(best_pipe, 'xgboost_model.joblib')\n",
        "files.download('xgboost_model.joblib')"
      ],
      "metadata": {
        "id": "S1kijgj1IyLI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "4c2bea82-e462-4ea3-b123-9c9d4d46bb26"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Chain] ................... (1 of 8) Processing order 0, total=  17.2s\n",
            "[Chain] ................... (2 of 8) Processing order 1, total=  15.2s\n",
            "[Chain] ................... (3 of 8) Processing order 2, total=  12.6s\n",
            "[Chain] ................... (4 of 8) Processing order 3, total=  12.9s\n",
            "[Chain] ................... (5 of 8) Processing order 4, total=  12.1s\n",
            "[Chain] ................... (6 of 8) Processing order 5, total=  14.9s\n",
            "[Chain] ................... (7 of 8) Processing order 6, total=  12.4s\n",
            "[Chain] ................... (8 of 8) Processing order 7, total=  14.2s\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f373bfec-1140-4d59-8dbf-4471a891ca9d\", \"xgboost_model.joblib\", 99749819)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}